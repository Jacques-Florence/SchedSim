[global]
reportsFolder = scratch
record = yes

[scheduler]
runningTime = 20000000
discipline = rlDiscipline
governor = minGovernor
temperatureModel = temperatureAndAging
randomSeed = 1
distribution = none

logTemperature = yes
onlyLogTempAfterRatio = 0.9999
thermalResistance = 2.0
thermalCapacitance = 20.0

logAging = yes
activationEnergy = 1.0 #in electron volts
formFactor = 1000000.0


[taskSet]
tasksetSource = random
#those are used for when using generateTaskSet function
utilization = 0.7
nbOfTasks = 10
seed = 789
priorities = yes
powerSpan = 10
[mdp]

costHorizon = average
learningStrategy = reinforcedLearning
solver = linearProgramming
discountFactor = 0.9
seed = 456
recordHistory = no

[reinforcementLearning]
alpha = 0.08
#alphaDecaySpeed = 0.9999
alphaDecaySpeed = 0.99999
epsilon = 0.999
epsilonDecaySpeed = 0.9999
epsilonTimeOut = 0
algo = QLearning
#algo = sarsaLambda
lambda = 0.0
initialActionValue = 0.0
alphaHyperbolicDecay = no
alphaStepwiseDecay = yes
alphaStepLength = 10000

recordActionValues = no
recordOnlyLastAction = yes
actionValuesRecorded = 1 3 4 5 7 9 10 11 12 13 14 15 16 19 22
actionValueRecordChunkSize = 10000

updatePolicy = yes

[mdpGovernor]
dimensions = readyQueueSize waitQueueSize

[rlDiscipline]
timeState = no
temperatureState = no
nbTemperatureStates = 16
#peakDecaySpeed = 0.99999999
peakDecaySpeed = 0.9999999

deadlineMissRewardCoeff = 1.0
tempRewardCoeff = 0.0
agingRewardCoeff = 10000.0

#maxTempEstimator = monomialMaxTempEstimator 3
#maxTempEstimator = envelopeDetector
maxTempEstimator = exponentialTempEstimator 0.1
tempLimit = 48


